{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"What is the average time taken to build instances in the past week for openstack-asia-pacific?","output":"[QL] avg(\n  avg_over_time(\n    {application=\"openstack-asia-pacific\", component=\"nova.compute.manager\"}\n    |~ \"Took .* seconds to build instance\"\n    | regexp \"Took (?P<build_time>[0-9.]+) seconds to build instance\"\n    | unwrap build_time [1w]\n  )\n) [\/QL] [EXPLANATION] 1. `{application=\"openstack-asia-pacific\", component=\"nova.compute.manager\"}`: This selects all logs from the OpenStack application, specifically from the nova.compute.manager component, which is responsible for instance management.\n\n2. `|~ \"Took .* seconds to build instance\"`: This line filter matches log lines containing the message about instance build time.\n\n3. `| regexp \"Took (?P<build_time>[0-9.]+) seconds to build instance\"`: This extracts the build time value into a label named \"build_time\".\n\n4. `| unwrap build_time`: This unwraps the \"build_time\" label, preparing it for numeric operations.\n\n5. `[1w]`: This specifies the one-week time range as requested in the question.\n\n6. `avg_over_time(...)`: This calculates the average of the build times over the specified time range for each unique combination of labels.\n\n7. `avg(...)`: This calculates the overall average across all instances, giving us a single value representing the average time taken to build instances in the past week.\n [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"How many times did the NameSystem update the blockMap in the past 6 hours for hdfs-eu-west?","output":"[QL] sum(count_over_time({application=\"hdfs-eu-west\", component=\"dfs.FSNamesystem\"} |~ \"BLOCK\\\\* NameSystem\\\\.addStoredBlock: blockMap updated:\" [6h])) [\/QL] [EXPLANATION] 1. `{application=\"hdfs-eu-west\", component=\"dfs.FSNamesystem\"}`: This selects all logs from the HDFS application and the FSNamesystem component, which handles NameSystem operations.\n\n2. `|~ \"BLOCK\\\\* NameSystem\\\\.addStoredBlock: blockMap updated:\"`: This line filter matches log lines containing the blockMap update event.\n\n3. `[6h]`: This specifies the 6-hour time range as requested in the question.\n\n4. `count_over_time(... [6h])`: This counts the occurrences of the matched log lines over the specified time range.\n\n5. `sum(...)`: This sums the counts across all instances, giving us the total number of blockMap updates.\n\nThis query efficiently counts the number of times the NameSystem updated the blockMap in the past 6 hours. The result will be a single value representing the total count of blockMap updates during this period.\n [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"Which DataNodes had the most failed block transfers in the last 24 hours for application hdfs-south-america?","output":"[QL] topk(3,\n  sum by (source_datanode) (\n    count_over_time(\n      {application=\"hdfs-south-america\"}\n      |~ \"Failed to transfer .* to .* got java.io.IOException: Connection reset by peer\"\n      | regexp \"(?P<source_datanode>[\\\\d\\\\.]+:\\\\d+):Failed to transfer .* to .* got java.io.IOException: Connection reset by peer\"\n      [24h]\n    )\n  )\n) [\/QL] [EXPLANATION] 1. `{application=\"hdfs-south-america\"}`: This selects all logs from the DataNode component for the application hdfs-south-america.\n\n2. `|~ \"Failed to transfer .* to .* got java.io.IOException: Connection reset by peer\"`: This line filter matches log lines containing the failed block transfer event.\n\n3. `| regexp \"(?P<source_datanode>[\\\\d\\\\.]+:\\\\d+):Failed to transfer .* to .* got java.io.IOException: Connection reset by peer\"`: This extracts the source DataNode IP and port using a regular expression and assigns it to the label \"source_datanode\".\n\n4. `[24h]`: This specifies the 24-hour time range as requested in the question.\n\n5. `count_over_time(...)`: This counts the occurrences of failed transfers for each unique source_datanode over the specified time range.\n\n6. `sum by (source_datanode) (...)`: This sums the counts for each unique source_datanode, giving us the total number of failed transfers for each DataNode.\n\n7. `topk(3, ...)`: This selects the top DataNode with the highest count of failed transfers.\n\nThis query efficiently identifies the DataNode that had the most failed block transfers in the last 24 hours for application hdfs-south-america. The result will show the DataNode IP:port and the count of failed transfers, with only the top (most failing) DataNode being returned.\n [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"How many connections were closed during the pre-authentication phase for the application openssh-eu-west, grouped by source IP address?","output":"[QL] sum by (source_ip) (\n  count_over_time({application=\"openssh-eu-west\", hostname=\"LabSZ\"} \n    |~ \"Connection closed by .* \\\\[preauth\\\\]\"\n    | regexp \"Connection closed by (?P<source_ip>\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+)\"\n    | __error__=\"\"\n    [24h]\n  )\n) [\/QL] [EXPLANATION] 1\n{application=\"openssh-eu-west\", hostname=\"LabSZ\"}\nFetch all log lines matching label filters.\n2\n<expr> |~ `Connection closed by .* \\[preauth\\]`\nReturn log lines that match a RE2 regex pattern. Connection closed by .* \\[preauth\\].\n\n3\n<expr> | regexp `Connection closed by (?P<source_ip>\\d+\\.\\d+\\.\\d+\\.\\d+)`\nThe regexp parser takes a single parameter | regexp \"<re>\" which is the regular expression using the Golang RE2 syntax. The regular expression must contain a least one named sub-match (e.g (?P<name>re)), each sub-match will extract a different label. The expression matches the structure of a log line. The extracted labels can be used in label filter expressions and used as values for a range aggregation via the unwrap operation.\n\n4\n<expr> | __error__=``\nFilter out all formatting and parsing errors.\n\n5\ncount_over_time(<expr> [24h])\nThe count of all values in the specified interval. The range vector is set to 24h.\n\n6\nsum by(source_ip) (<expr>)\nCalculates sum over dimensions while preserving label source_ip. [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"How many instances were terminated on compute node cp-1.slowvm1.tcloud-pg0.utah.cloudlab.us yesterday for application openstack-tenant-1?","output":"[QL] sum(count_over_time({application=\"openstack-tenant-1\", log_file_type=\"nova-compute\", component=\"nova.compute.manager\"}\n|= \"cp-1.slowvm1.tcloud-pg0.utah.cloudlab.us\"\n|= \"Terminating instance\"\n[1d] offset 1d)) [\/QL] [EXPLANATION] 1\n{application=\"openstack-tenant-1\", log_file_type=\"nova-compute\", component=\"nova.compute.manager\"}\nFetch all log lines matching label filters.\n2\n<expr> |= `cp-1.slowvm1.tcloud-pg0.utah.cloudlab.us`\nReturn log lines that contain string cp-1.slowvm1.tcloud-pg0.utah.cloudlab.us.\n\n3\n<expr> |= `Terminating instance`\nReturn log lines that contain string Terminating instance.\n\n4\ncount_over_time(<expr> [1d])\nThe count of all values in the specified interval. The range vector is set to 1d.\n\n5\nsum(<expr>)\nCalculates sum over the dimensions. [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"Which source IP had the highest number of successful block transmissions in the last 12 hours for application hdfs-asia-pacific?","output":"[QL] topk(1,\n  sum by (source_ip) (\n    count_over_time(\n      {application=\"hdfs-asia-pacific\", component=\"dfs.DataNode$DataTransfer\"}\n      |~ \"Transmitted block .* to .*\"\n      | regexp \"(?P<source_ip>[\\\\d\\\\.]+):\\\\d+:Transmitted block .* to .*\"\n      [12h]\n    )\n  )\n) [\/QL] [EXPLANATION] Explanation of the query:\n\n1. `{application=\"hdfs-asia-pacific\", component=\"dfs.DataNode$DataTransfer\"}`: This selects all logs from the HDFS application and the DataNode's DataTransfer component, which handles data transfer operations.\n\n2. `|~ \"Transmitted block .* to .*\"`: This line filter matches log lines containing successful block transmission events.\n\n3. `| regexp \"(?P<source_ip>[\\\\d\\\\.]+):\\\\d+:Transmitted block .* to .*\"`: This extracts the source IP address using a regular expression and assigns it to the label \"source_ip\". Note that we're capturing only the IP part, not the port.\n\n4. `[12h]`: This specifies the 12-hour time range as requested in the question.\n\n5. `count_over_time(...)`: This counts the occurrences of each unique source_ip over the specified time range.\n\n6. `sum by (source_ip) (...)`: This sums the counts for each unique source_ip, giving us the total number of successful block transmissions for each source IP.\n\n7. `topk(1, ...)`: This selects the top 1 source IP with the highest count of successful block transmissions.\n\nThis query efficiently identifies the source IP that had the highest number of successful block transmissions in the last 12 hours. The result will show the source IP and the count of successful block transmissions.\n [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"Which DataNodes had the highest number of 'Broken pipe' exceptions in PacketResponder threads in the past 12 hours for application 'hdfs-eu-central'?","output":"[QL] {component=\"dfs.DataNode$PacketResponder\", log_level=\"INFO\", application=\"hdfs-eu-central\"} |~ \"PacketResponder .* Exception java.io.IOException: Broken pipe\"\n      | regexp \"(?P<datanode>\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+:\\\\d+).*PacketResponder .* Exception java.io.IOException: Broken pipe\" [\/QL] [EXPLANATION] Explanation of the query:\n\n1. `{component=\"dfs.DataNode$PacketResponder\", log_level=\"INFO\", application=\"hdfs-eu-central\"}`: This selects all logs from the PacketResponder component with INFO log level for the application 'hdfs-eu-central'.\n\n2. `|~ \"PacketResponder .* Exception java.io.IOException: Broken pipe\"`: This line filter matches log lines containing the 'Broken pipe' exception in PacketResponder.\n\n3. `| regexp \"(?P<datanode>\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+:\\\\d+).*PacketResponder .* Exception java.io.IOException: Broken pipe\"`: This extracts the DataNode IP and port using a regular expression and assigns it to the label \"datanode\". We assume the DataNode information is at the beginning of the log line, which is common in distributed system logs. [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"How many instances of 'HTTP exception thrown: No instances found for any event' occurred in the nova-api logs in the last 40 days for the application 'openstack-asia-pacific'?","output":"[QL] sum by (application)\n(count_over_time({application=\"openstack-asia-pacific\", log_file_type=\"nova-api\", log_level=\"INFO\"}\n|= \"HTTP exception thrown: No instances found for any event\"\n[40d])) [\/QL] [EXPLANATION] 1\n{application=\"openstack-asia-pacific\", log_file_type=\"nova-api\", log_level=\"INFO\"}\nFetch all log lines matching label filters.\n2\n<expr> |= `HTTP exception thrown: No instances found for any event`\nReturn log lines that contain string HTTP exception thrown: No instances found for any event.\n\n3\ncount_over_time(<expr> [40d])\nThe count of all values in the specified interval. The range vector is set to 40d.\n\n4\nsum by(application) (<expr>)\nCalculates sum over dimensions while preserving label application. [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"How many POST requests to \/v2\/{tenant_id}\/os-server-external-events resulted in a 500 status code in the past 24 hours for the application openstack-tenant-2?","output":"[QL] sum(count_over_time({application=\"openstack-tenant-2\"}\n |= \"POST\"\n |= \"\/v2\/\"\n |= \"\/os-server-external-events\"\n |= \"status: 500\"\n[24h])) [\/QL] [EXPLANATION] 1. `{application=\"openstack-tenant-2\", log_file_type=\"nova-api\"}`: This selects all logs from the OpenStack application, specifically from the nova-api log file type, which handles API requests.\n\n2. `|= \"POST\"`: This line filter matches log lines containing POST requests.\n\n3. `|= \"\/v2\/\"`: This line filter matches log lines containing \"\/v2\/\" in the URL path.\n\n4. `|= \"\/os-server-external-events\"`: This line filter matches log lines containing the specific endpoint we're interested in.\n\n5. `|= \"status: 500\"`: This line filter matches log lines where the status code is 500.\n\n6. `[24h]`: This specifies the 24-hour time range as requested in the question.\n\n7. `count_over_time(...)`: This counts the occurrences of matching log lines over the specified time range.\n\n8. `sum(...)`: This sums up all the counts, giving us the total number of POST requests to the specified endpoint that resulted in a 500 status code in the past 24 hours. [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"How many connections were closed during the pre-authentication phase for the application openssh-us-east, grouped by source IP address?","output":"[QL] sum by (source_ip) (\n  count_over_time({application=\"openssh-us-east\", hostname=\"LabSZ\"} \n    |~ \"Connection closed by .* \\\\[preauth\\\\]\"\n    | regexp \"Connection closed by (?P<source_ip>\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+)\"\n    | __error__=\"\"\n    [24h]\n  )\n) [\/QL] [EXPLANATION] 1\n{application=\"openssh-us-east\", hostname=\"LabSZ\"}\nFetch all log lines matching label filters.\n2\n<expr> |~ `Connection closed by .* \\[preauth\\]`\nReturn log lines that match a RE2 regex pattern. Connection closed by .* \\[preauth\\].\n\n3\n<expr> | regexp `Connection closed by (?P<source_ip>\\d+\\.\\d+\\.\\d+\\.\\d+)`\nThe regexp parser takes a single parameter | regexp \"<re>\" which is the regular expression using the Golang RE2 syntax. The regular expression must contain a least one named sub-match (e.g (?P<name>re)), each sub-match will extract a different label. The expression matches the structure of a log line. The extracted labels can be used in label filter expressions and used as values for a range aggregation via the unwrap operation.\n\n4\n<expr> | __error__=``\nFilter out all formatting and parsing errors.\n\n5\ncount_over_time(<expr> [24h])\nThe count of all values in the specified interval. The range vector is set to 24h.\n\n6\nsum by(source_ip) (<expr>)\nCalculates sum over dimensions while preserving label source_ip. [\/EXPLANATION]"}
{"instruction":"You are LogQLLM, a specialized language model trained to convert natural language queries into LogQL (Log Query Language) queries. Your primary function is to interpret user requests expressed in plain English and translate them into valid LogQL syntax.","input":"What is the distribution of SSH disconnection reasons across all hosts in the last 24 hours for openssh-apac-2?","output":"[QL] sum by (reason) (\n  count_over_time({application=\"openssh-apac-2\", hostname=\"HostE\"} \n    |~ \"Received disconnect from|Disconnecting:|error: Received disconnect from\" \n    | regexp \"(?P<reason>(Received disconnect from [^:]+: (?P<code>\\\\d+): (?P<message>[^\\\\[]+))|(Disconnecting: [^\\\\[]+)|(error: Received disconnect from [^:]+: (?P<error_code>\\\\d+): (?P<error_message>.+)))\"\n    | label_format reason=\"{{ or .message .reason .error_message }}\"\n    [24h])\n) [\/QL] [EXPLANATION] 1\n{application=\"openssh-apac-2\", hostname=\"HostE\"}\nFetch all log lines matching label filters.\n2\n<expr> |~ `Received disconnect from|Disconnecting:|error: Received disconnect from`\nReturn log lines that match a RE2 regex pattern. Received disconnect from|Disconnecting:|error: Received disconnect from.\n\n3\n<expr> | regexp `(?P<reason>(Received disconnect from [^:]+: (?P<code>\\d+): (?P<message>[^\\[]+))|(Disconnecting: [^\\[]+)|(error: Received disconnect from [^:]+: (?P<error_code>\\d+): (?P<error_message>.+)))`\nThe regexp parser takes a single parameter | regexp \"<re>\" which is the regular expression using the Golang RE2 syntax. The regular expression must contain a least one named sub-match (e.g (?P<name>re)), each sub-match will extract a different label. The expression matches the structure of a log line. The extracted labels can be used in label filter expressions and used as values for a range aggregation via the unwrap operation.\n\n4\n<expr> | label_format reason=\"{{ or .message .reason .error_message }}\"\nThis will change name of label to desired new label. In the example below, label \"error_level\" will be renamed to \"level\".\n\nExample: error_level=`level`\n\nRead the docs for more.\n\n5\ncount_over_time(<expr> [24h])\nThe count of all values in the specified interval. The range vector is set to 24h.\n\n6\nsum by(reason) (<expr>)\nCalculates sum over dimensions while preserving label reason. [\/EXPLANATION]"}
